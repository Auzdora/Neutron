{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Tensor core documents__\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">Tensor core is the basic data structure in Neutron. It has handle for CPU and GPU sub-data structure, numpy and Quark respectively. Numpy is the python built-in scientific computation pack and Quark is the CUDA accelerated computation's basic elements. In this documents, it'll show you how Tensor class can control both CPU and GPU data together and realize specific operation in Deep learning framework.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font face=\"Consolas\">Quark data structure is defined in the 'src/array.h' by using struct data structure. It contains four parameters that are useful while computing in the back-end, which is GPU. \n",
    "\n",
    "```Python\n",
    "class Quark(ctypes.Structure):\n",
    "    \"\"\"\n",
    "        C++ back-end data structure. Contains data pointer (numpy data type has to\n",
    "        be float32, otherwise it'll raise calculate error), device, data shape poin\n",
    "        ter and dimension.\n",
    "    \"\"\"\n",
    "    _fields_ = [('data', ctypes.POINTER(c_float)),\n",
    "                ('device', ctypes.c_int),\n",
    "                ('shape', ctypes.POINTER(ctypes.c_int)),\n",
    "                ('dim', ctypes.c_int)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">Tensor class the most important attribute is the handle. In English, handle is something that you can grab it in a very easy way but you can get lots of useful information or things connected with the handle. The same idea in Neutron. You can simply access data, data shape, data dim and device information through handle.\n",
    "\n",
    "```Python\n",
    "class Tensor:\n",
    "    \"\"\"\n",
    "        Python fore-end data structure.\n",
    "        The most important attr is handle. Handle is a pointer to the real data str\n",
    "        -ucture. It manages GPU data structure (Quark) and CPU data structure (numpy).\n",
    "        \n",
    "        When you instantiate the Tensor, you need to give parameters as follows:\n",
    "        1. data: numpy array, dtype is np.float32.\n",
    "        2. device: on cpu or on gpu.\n",
    "        3. require_grad: require calculate gradient or not.\n",
    "    \"\"\"\n",
    "    __slots__ = ['handle','device','require_grad']\n",
    "\n",
    "    def __init__(self, data, device=CPU, require_grad=False):\n",
    "        self.device = device\n",
    "        self.require_grad = require_grad\n",
    "        self.handle = self.configureHandle(self, data, device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">To get shape and data, it needs some special function called property function.\n",
    "```Python\n",
    "    @property\n",
    "    def shape(self):  # get data shape\n",
    "        if isinstance(self.handle, ndarray):\n",
    "            return self.handle.shape\n",
    "        return tuple([self.handle.shape[idx] for idx in range(self.handle.dim)])\n",
    "    \n",
    "    @property\n",
    "    def data(self):  # get data\n",
    "        assert(self.device == GPU), \"the data on the gpu instead of cpu\"\n",
    "        return np.ctypeslib.as_array(self.handle.data, shape=self.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font face=\"Consolas\">\n",
    "\n",
    "ConfigureHandle() is used for set value of self.handle. It has two modes, CPU mode and GPU mode. getNumpyHandle() just simply return the numpy array. getQuarkHandle() is a little bit complex.\n",
    "The routine of getQuarkHandle():\n",
    "1. get numpy array's information, data, shape, dim.\n",
    "2. create a Quark and initialize it.\n",
    "3. start to allocate and copy data to GPU (this include some CUDALib's function, please refer to CUDALib documents).\n",
    "4. return the Quark data structure.\n",
    "\n",
    "</font>\n",
    "\n",
    "```Python\n",
    "    @staticmethod\n",
    "    # configure the handle attribute\n",
    "    def configureHandle(self, data, device):\n",
    "        if device == GPU:\n",
    "            return self.getQuarkHandle(data)\n",
    "        elif device == CPU:\n",
    "            return self.getNumpyHandle(data)\n",
    "    \n",
    "    @staticmethod\n",
    "    # get the Quark data structure handle\n",
    "    def getQuarkHandle(numpy_data):\n",
    "        assert isinstance(numpy_data, ndarray), \"input data should be numpy array\"\n",
    "        data = numpy_data\n",
    "        arr = Quark()\n",
    "        arr.data = data.ctypes.data_as(ctypes.POINTER(c_float))\n",
    "        arr.device = GPU\n",
    "        arr.shape = getShape(ctypes.c_int, data.shape)\n",
    "        arr.dim = len(data.shape)\n",
    "         \n",
    "        # start to allocate and copy data to GPU\n",
    "        size = CUDALib.getSize(arr.dim, arr.shape)\n",
    "        dev_ptr = CUDALib.AllocateDeviceData(size)\n",
    "        CUDALib.CopyDataFromTo(arr.data, dev_ptr, CPU, GPU, size)\n",
    "        arr.data = dev_ptr\n",
    "        return arr\n",
    "        \n",
    "    @staticmethod\n",
    "    # get the numpy data structure handle4\n",
    "    def getNumpyHandle(numpy_data):\n",
    "        assert isinstance(numpy_data, ndarray), \"input data should be numpy array\"\n",
    "        return numpy_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">\n",
    "\n",
    "It also enables users to tranfer data through CPU and GPU, that needs to decode and get data, shape and dim and reconstruct oppsite data structure.\n",
    "\n",
    "```Python\n",
    "    # transfer the data from the gpu to the cpu\n",
    "    def cpu(self):\n",
    "        if self.device == GPU:\n",
    "            size = CUDALib.getSize(self.handle.dim, self.handle.shape)\n",
    "            host_ptr = CUDALib.AllocateHostData(size)\n",
    "            CUDALib.CopyDataFromTo(self.handle.data, host_ptr, GPU, CPU, size)\n",
    "            self.handle.data = host_ptr\n",
    "        return self\n",
    "    \n",
    "    # transfer the data from the cpu to the gpu\n",
    "    def gpu(self):\n",
    "        if self.device == CPU and isinstance(self.handle, ndarray):\n",
    "            self.handle = self.getQuarkHandle(self.handle)\n",
    "        return self\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Use GPU and Tensor to compute__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">First we need to import some important package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import Tensor\n",
    "from core import *\n",
    "import numpy as np\n",
    "from ctypes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">And then we need create two input numpy arrays and one output numpy array. After that we can create three GPU tensor by declaring that device=GPU, the back-end will allocate and copy the numpy array data to the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [3, 4, 5]], dtype=np.float32)\n",
    "b = np.array([[2, 2, 9], [1, 1, 1]], dtype=np.float32)\n",
    "c = np.zeros((2, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Tensor(a, device=GPU)\n",
    "input2 = Tensor(b, device=GPU)\n",
    "output = Tensor(c, device=GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">Then we can call cudaAdd() function defined in core/_CUDA_OP.py to compute using GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaAdd(input1, input2, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">While the output data are still on the GPU, so you can't directly print and see. Fortunately, Tensor class provide an easy interface to help you transfer the GPU data to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[ 3.  4. 12.]\n",
      " [ 4.  5.  6.]], shape=(2, 3), dtype=Tensor.float32)\n"
     ]
    }
   ],
   "source": [
    "output.cpu()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Consolas\">There are plenty of GPU operator defined in core/_CUDA_OP.py. If you wanna try something more, follow the coding model above all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "256c8266944fffc66b3c54b5db1fac02d8d0829eefb9c2d0148b4d5ab10919b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
